text_in <- get(text_name)
coverage <- sum(text_in$sentiment == "assigned") / nrow(text_in)
print(paste("Coverage for", text_name, ":", coverage))
}
read_csv = read.csv(here("05_output", "1_vader_scores.csv"))
merger <- read_csv %>% select(tokenindex, token, polarity_score, sentiment)
total <- merge(text1, merger, by=c("tokenindex", "token")) %>%
group_by(textnr, participant_id) %>%
arrange(tokenindex, .by_group = TRUE)
for (text_name in texts_listed) {
text_in <- get(text_name)
coverage <- sum(text_in$sentiment != 0.00) / nrow(text_in)
print(paste("Coverage for", text_name, ":", coverage))
}
for (text_name in texts_listed) {
text_in <- get(text_name)
coverage <- sum(text_in$sentiment != 0.00) / nrow(text_in) *100
print(paste("Coverage for", text_name, ":", coverage, "%"))
}
for (text_name in texts_listed) {
text_in <- get(text_name)
coverage <- sum(text_in$sentiment != 0.00) / nrow(text_in) *100
print(paste("Coverage for", text_name, ":", round(coverage,0), "%"))
}
for (text_name in texts_listed) {
text_in <- get(text_name)
coverage <- sum(text_in$sentiment != 0.00) / nrow(text_in) *100
print(paste0("Coverage for ", text_name, ": ", round(coverage,0), "%"))
}
for (text_name in texts_listed) {
text_in <- get(text_name)
coverage <- sum(text_in$sentiment != 0.00) / nrow(text_in) *100
print(paste0("Coverage for ANEW ratings in", text_name, ": ", round(coverage,0), "%"))
}
for (text_name in texts_listed) {
text_in <- get(text_name)
coverage <- sum(text_in$sentiment != 0.00) / nrow(text_in) *100
print(paste0("Coverage for ANEW ratings in ", text_name, ": ", round(coverage,0), "%"))
}
knitr::opts_chunk$set(echo = TRUE)
here::i_am("03_Rmd/Preprocessing.Rmd")
library(here)
library(dplyr)
library(reticulate)
library(quanteda)
library(quanteda.sentiment)
library(tidyr)
use_condaenv("thesis23")
load(here("01_data", "meco L2", "primary data","eye tracking data","joint_data_l2_trimmed.rda"))
eye_table <- joint.data %>% select(uniform_id, lang, itemid, ianum, ia, skip, nfix, refix, dur, firstrun.dur, firstrun.gopast, firstrun.gopast.sel, firstfix.dur)
eye_table <- eye_table %>% rename("participant_id" = "uniform_id", "textnr" = "itemid", "tokenindex" = "ianum", "token"="ia")
eye_table <- eye_table %>% group_by(textnr, participant_id) %>% arrange(tokenindex, .by_group = TRUE) %>% distinct()
text_table <- function(nr){
return(subset(eye_table, subset = textnr == nr))
}
text1 <- text_table(1)
text2 <- text_table(2)
text3 <- text_table(3)
text4 <- text_table(4)
text5 <- text_table(5)
text6 <- text_table(6)
text7 <- text_table(7)
text8 <- text_table(8)
text9 <- text_table(9)
text10 <- text_table(10)
text11 <- text_table(11)
text12 <- text_table(12)
source(here("04_scripts","02_anew.R"), local = knitr::knit_global())
#lapply(valence(data_dictionary_ANEW), head)
#pleasure <- valence(data_dictionary_ANEW)[["pleasure"]]
texts_listed <- list("text1", "text2", "text3", "text4", "text5", "text6", "text7", "text8", "text9", "text10", "text11", "text12")
for (text_name in texts_listed) {
add_anew_score(text_name)
text_name %>% rename("sentiment" = "anew_score")
}
source(here("04_scripts","02_anew.R"), local = knitr::knit_global())
#lapply(valence(data_dictionary_ANEW), head)
#pleasure <- valence(data_dictionary_ANEW)[["pleasure"]]
texts_listed <- list("text1", "text2", "text3", "text4", "text5", "text6", "text7", "text8", "text9", "text10", "text11", "text12")
for (text_name in texts_listed) {
add_anew_score(text_name)
text_name %>% rename("anew_score" = "sentiment")
}
knitr::opts_chunk$set(echo = TRUE)
here::i_am("03_Rmd/Preprocessing.Rmd")
library(here)
library(dplyr)
library(reticulate)
library(quanteda)
library(quanteda.sentiment)
library(tidyr)
use_condaenv("thesis23")
load(here("01_data", "meco L2", "primary data","eye tracking data","joint_data_l2_trimmed.rda"))
eye_table <- joint.data %>% select(uniform_id, lang, itemid, ianum, ia, skip, nfix, refix, dur, firstrun.dur, firstrun.gopast, firstrun.gopast.sel, firstfix.dur)
eye_table <- eye_table %>% rename("participant_id" = "uniform_id", "textnr" = "itemid", "tokenindex" = "ianum", "token"="ia")
eye_table <- eye_table %>% group_by(textnr, participant_id) %>% arrange(tokenindex, .by_group = TRUE) %>% distinct()
text_table <- function(nr){
return(subset(eye_table, subset = textnr == nr))
}
text1 <- text_table(1)
text2 <- text_table(2)
text3 <- text_table(3)
text4 <- text_table(4)
text5 <- text_table(5)
text6 <- text_table(6)
text7 <- text_table(7)
text8 <- text_table(8)
text9 <- text_table(9)
text10 <- text_table(10)
text11 <- text_table(11)
text12 <- text_table(12)
source(here("04_scripts","02_anew.R"), local = knitr::knit_global())
#lapply(valence(data_dictionary_ANEW), head)
#pleasure <- valence(data_dictionary_ANEW)[["pleasure"]]
texts_listed <- list("text1", "text2", "text3", "text4", "text5", "text6", "text7", "text8", "text9", "text10", "text11", "text12")
for (text_name in texts_listed) {
add_anew_score(text_name)
text_name %>% rename("anew_score" = "sentiment")
}
knitr::opts_chunk$set(echo = TRUE)
here::i_am("03_Rmd/Preprocessing.Rmd")
library(here)
library(dplyr)
library(reticulate)
library(quanteda)
library(quanteda.sentiment)
library(tidyr)
use_condaenv("thesis23")
load(here("01_data", "meco L2", "primary data","eye tracking data","joint_data_l2_trimmed.rda"))
eye_table <- joint.data %>% select(uniform_id, lang, itemid, ianum, ia, skip, nfix, refix, dur, firstrun.dur, firstrun.gopast, firstrun.gopast.sel, firstfix.dur)
eye_table <- eye_table %>% rename("participant_id" = "uniform_id", "textnr" = "itemid", "tokenindex" = "ianum", "token"="ia")
eye_table <- eye_table %>% group_by(textnr, participant_id) %>% arrange(tokenindex, .by_group = TRUE) %>% distinct()
text_table <- function(nr){
return(subset(eye_table, subset = textnr == nr))
}
text1 <- text_table(1)
text2 <- text_table(2)
text3 <- text_table(3)
text4 <- text_table(4)
text5 <- text_table(5)
text6 <- text_table(6)
text7 <- text_table(7)
text8 <- text_table(8)
text9 <- text_table(9)
text10 <- text_table(10)
text11 <- text_table(11)
text12 <- text_table(12)
source(here("04_scripts","02_anew.R"), local = knitr::knit_global())
#lapply(valence(data_dictionary_ANEW), head)
#pleasure <- valence(data_dictionary_ANEW)[["pleasure"]]
texts_listed <- list("text1", "text2", "text3", "text4", "text5", "text6", "text7", "text8", "text9", "text10", "text11", "text12")
for (text_name in texts_listed) {
add_anew_score(text_name)
}
for (text_name in texts_listed) {
text_in <- get(text_name)
coverage <- sum(text_in$sentiment != 0.00) / nrow(text_in) *100
print(paste0("Coverage for ANEW ratings in ", text_name, ": ", round(coverage,0), "%"))
}
read_csv = read.csv(here("05_output", "1_vader_scores.csv"))
merger <- read_csv %>% select(tokenindex, token, polarity_score, sentiment)
total <- merge(text1, merger, by=c("tokenindex", "token")) %>%
group_by(textnr, participant_id) %>%
arrange(tokenindex, .by_group = TRUE)
for (text_name in texts_listed) {
text_in <- get(text_name)
coverage <- sum(text_in$anew_score != 0.00) / nrow(text_in) *100
print(paste0("Coverage for ANEW ratings in ", text_name, ": ", round(coverage,0), "%"))
}
View(text1)
print("Coverage")
for (text_name in texts_listed) {
text_in <- get(text_name)
coverage <- sum(text_in$anew_score != 0.00) / nrow(text_in) *100
print(paste0("ANEW ratings in ", text_name, ": ", round(coverage,0), "%"))
}
View(total)
source_python(here("04_scripts", "01_vader.py"))
for (nr in 1:text_outputs){
assign_polarity_score(nr)
}
text_outputs = 12
for (nr in 1:text_outputs){
out <- get(paste0("text", nr)) %>% ungroup() %>% select(textnr, tokenindex, token) %>% distinct()
write.csv(out, here("05_output", paste0(nr, "_text_tokens.csv")))
}
source_python(here("04_scripts", "01_vader.py"))
for (nr in 1:text_outputs){
assign_polarity_score(nr)
}
read_csv = read.csv(here("05_output", "1_vader_scores.csv"))
merger <- read_csv %>% select(tokenindex, token, polarity_score, sentiment)
read_csv = read.csv(here("05_output", "1_vader_scores.csv"))
merger <- read_csv %>% select(tokenindex, token, vader_score, sentiment)
total <- merge(text1, merger, by=c("tokenindex", "token")) %>%
group_by(textnr, participant_id) %>%
arrange(tokenindex, .by_group = TRUE)
text_outputs = 12
for (nr in 1:text_outputs){
out <- get(paste0("text", nr)) %>% ungroup() %>% select(textnr, tokenindex, token) %>% distinct()
write.csv(out, here("05_output", paste0(nr, "_text_tokens.csv")))
}
source_python(here("04_scripts", "01_vader.py"))
for (nr in 1:text_outputs){
assign_polarity_score(nr)
}
read_csv = read.csv(here("05_output", "1_vader_scores.csv"))
merger <- read_csv %>% select(tokenindex, token, vader_score, vader_polarity)
total <- merge(text1, merger, by=c("tokenindex", "token")) %>%
group_by(textnr, participant_id) %>%
arrange(tokenindex, .by_group = TRUE)
source_python(here("04_scripts", "01_vader.py"))
for (nr in 1:text_outputs){
assign_polarity_score(nr)
}
#read_csv = read.csv(here("05_output", "1_vader_scores.csv"))
#merger <- read_csv %>% select(tokenindex, token, vader_score, vader_polarity)
#total <- merge(text1, merger, by=c("tokenindex", "token")) %>%
#group_by(textnr, participant_id) %>%
#arrange(tokenindex, .by_group = TRUE)
vader_scores_list <- list()
# Loop through the files and read them into the list
for (i in 1:12) {
file_path <- here("05_output", paste0(i, "_vader_scores.csv"))
# Check if the file exists before attempting to read it
if (file.exists(file_path)) {
vader_scores_list[[i]] <- read.csv(file_path)
merger <- read_csv %>% select(tokenindex, token, vader_score, vader_polarity)
total <- merge(get(paste0("text",i)), merger, by=c("tokenindex", "token")) %>%
group_by(textnr, participant_id) %>%
arrange(tokenindex, .by_group = TRUE)
} else {
cat("File", file_path, "does not exist.\n")
}
}
View(vader_scores_list)
View(vader_scores_list[[1]])
View(text1)
#read_csv = read.csv(here("05_output", "1_vader_scores.csv"))
#merger <- read_csv %>% select(tokenindex, token, vader_score, vader_polarity)
#total <- merge(text1, merger, by=c("tokenindex", "token")) %>%
#group_by(textnr, participant_id) %>%
#arrange(tokenindex, .by_group = TRUE)
vader_scores_list <- list()
# Loop through the files and read them into the list
for (i in 1:12) {
file_path <- here("05_output", paste0(i, "_vader_scores.csv"))
# Check if the file exists before attempting to read it
if (file.exists(file_path)) {
vader_scores_list[[i]] <- read.csv(file_path)
merger <- vader_scores_list[[i]] %>% select(tokenindex, token, vader_score, vader_polarity)
total <- merge(get(paste0("text",i)), merger, by=c("tokenindex", "token")) %>%
group_by(textnr, participant_id) %>%
arrange(tokenindex, .by_group = TRUE)
} else {
cat("File", file_path, "does not exist.\n")
}
}
View(vader_scores_list)
#read_csv = read.csv(here("05_output", "1_vader_scores.csv"))
#merger <- read_csv %>% select(tokenindex, token, vader_score, vader_polarity)
#total <- merge(text1, merger, by=c("tokenindex", "token")) %>%
#group_by(textnr, participant_id) %>%
#arrange(tokenindex, .by_group = TRUE)
vader_scores_list <- list()
# Loop through the files and read them into the list
for (i in 1:12) {
file_path <- here("05_output", paste0(i, "_vader_scores.csv"))
# Check if the file exists before attempting to read it
if (file.exists(file_path)) {
vader_scores <- read.csv(file_path)
text_name <- paste0("text", i)
text_df <- get(text_name)
# Merge the data frame with its corresponding VADER scores
text_df <- merge(text_df, vader_scores, by = c("tokenindex", "token"))
# Group and arrange as needed
text_df <- text_df %>%
group_by(textnr, participant_id) %>%
arrange(tokenindex, .by_group = TRUE)
# Update the original data frame
assign(text_name, text_df, envir = .GlobalEnv)
} else {
cat("File", file_path, "does not exist.\n")
}
}
View(text1)
# Loop through the files and read them into the list
for (i in 1:10) {  # Assuming you have files from 1_vader_scores.csv to 10_vader_scores.csv
file_path <- here("05_output", paste0(i, "_vader_scores.csv"))
# Check if the file exists before attempting to read it
if (file.exists(file_path)) {
vader_scores <- read.csv(file_path)
# Assuming you have text1, text2, ..., text10 data frames
text_name <- paste0("text", i)
text_df <- get(text_name)
# Merge the data frame with its corresponding VADER scores
text_df <- merge(text_df, vader_scores, by = c("tokenindex", "token"))
# Check if the data frame has any rows before attempting to group it
if (nrow(text_df) > 0) {
# Check if the columns exist before attempting to group by them
group_by_cols <- c("textnr", "participant_id")
if (all(group_by_cols %in% names(text_df))) {
# Group and arrange as needed
text_df <- text_df %>%
group_by(across(all_of(group_by_cols))) %>%
arrange(tokenindex, .by_group = TRUE)
# Update the original data frame
assign(text_name, text_df, envir = .GlobalEnv)
} else {
cat("Columns", paste(setdiff(group_by_cols, names(text_df)), collapse = ", "), "not found in", text_name, ". Skipping grouping.\n")
}
} else {
cat("Data frame", text_name, "has no rows. Skipping grouping.\n")
}
} else {
cat("File", file_path, "does not exist.\n")
}
}
#read_csv = read.csv(here("05_output", "1_vader_scores.csv"))
#merger <- read_csv %>% select(tokenindex, token, vader_score, vader_polarity)
#total <- merge(text1, merger, by=c("tokenindex", "token")) %>%
#group_by(textnr, participant_id) %>%
#arrange(tokenindex, .by_group = TRUE)
# Loop through the files and read them into the list
for (i in 1:12) {
file_path <- here("05_output", paste0(i, "_vader_scores.csv"))
# Check if the file exists before attempting to read it
if (file.exists(file_path)) {
vader_scores <- read.csv(file_path)
merger <- vader_scores %>% select(tokenindex, token, vader_score, vader_polarity)
text_name <- get(paste0("text", i))
# Merge the data frame with its corresponding VADER scores
total <- merge(text_name, merger, by = c("tokenindex", "token")) %>%
group_by(textnr, participant_id) %>%
arrange(tokenindex, .by_group = TRUE)
} else {
cat("File", file_path, "does not exist.\n")
}
}
View(text_name)
View(text_df)
View(merger)
View(merger)
View(text_df)
#read_csv = read.csv(here("05_output", "1_vader_scores.csv"))
#merger <- read_csv %>% select(tokenindex, token, vader_score, vader_polarity)
#total <- merge(text1, merger, by=c("tokenindex", "token")) %>%
#group_by(textnr, participant_id) %>%
#arrange(tokenindex, .by_group = TRUE)
# Loop through the files and read them into the list
for (i in 1:12) {
file_path <- here("05_output", paste0(i, "_vader_scores.csv"))
# Check if the file exists before attempting to read it
if (file.exists(file_path)) {
vader_scores <- read.csv(file_path)
merger <- vader_scores %>% select(tokenindex, token, vader_score, vader_polarity)
text_name <- paste0("text", i)
# Merge the data frame with its corresponding VADER scores
text_df <- get(text_name)
text_df <- merge(text_df, merger, by = c("tokenindex", "token")) %>%
group_by(textnr, participant_id) %>%
arrange(tokenindex, .by_group = TRUE)
# Update the original data frame
assign(text_name, text_df, envir = .GlobalEnv)
} else {
cat("File", file_path, "does not exist.\n")
}
}
View(text9)
print("Coverage")
for (text_name in texts_listed) {
text_in <- get(text_name)
coverage_anew <- sum(text_in$anew_score != 0.00) / nrow(text_in) *100
print(paste0("ANEW ratings in ", text_name, ": ", round(coverage_anew,0), "%"))
coverage_vader <- sum(text_in$vader_score != 0.00) / nrow(text_in) *100
print(paste0("VADER ratings in ", text_name, ": ", round(coverage_vader,0), "%"))
print("\n")
}
print("Coverage")
for (text_name in texts_listed) {
text_in <- get(text_name)
coverage_anew <- sum(text_in$anew_score != 0.00) / nrow(text_in) *100
print(paste0("ANEW ratings in ", text_name, ": ", round(coverage_anew,0), "%"))
coverage_vader <- sum(text_in$vader_score != 0.00) / nrow(text_in) *100
print(paste0("VADER ratings in ", text_name, ": ", round(coverage_vader,0), "%"))
print("")
}
print("Coverage")
for (text_name in texts_listed) {
text_in <- get(text_name)
coverage_anew <- sum(text_in$anew_score != 0.00) / nrow(text_in) *100
print(paste0("ANEW ratings in ", text_name, ": ", round(coverage_anew,0), "%"))
coverage_vader <- sum(text_in$vader_score != 0.00) / nrow(text_in) *100
print(paste0("VADER ratings in ", text_name, ": ", round(coverage_vader,0), "%"))
print()
}
print("Coverage")
for (text_name in texts_listed) {
text_in <- get(text_name)
coverage_anew <- sum(text_in$anew_score != 0.00) / nrow(text_in) *100
print(paste0("ANEW ratings in ", text_name, ": ", round(coverage_anew,0), "%"))
coverage_vader <- sum(text_in$vader_score != 0.00) / nrow(text_in) *100
print(paste0("VADER ratings in ", text_name, ": ", round(coverage_vader,0), "%"))
print('')
}
print("Coverage")
for (text_name in texts_listed) {
text_in <- get(text_name)
coverage_anew <- sum(text_in$anew_score != 0.00) / nrow(text_in) *100
print(paste0("ANEW ratings in ", text_name, ": ", round(coverage_anew,0), "%"))
coverage_vader <- sum(text_in$vader_score != 0.00) / nrow(text_in) *100
print(paste0("VADER ratings in ", text_name, ": ", round(coverage_vader,0), "%"))
}
print("Coverage")
for (text_name in texts_listed) {
text_in <- get(text_name)
coverage_anew <- sum(text_in$anew_score != 0.00) / nrow(text_in) *100
print(paste0("ANEW ratings in ", text_name, ": ", round(coverage_anew,0), "%"))
coverage_vader <- sum(text_in$vader_score != 0.00) / nrow(text_in) *100
print(paste0("VADER ratings in ", text_name, ": ", round(coverage_vader,0), "%"))
}
print("Coverage")
for (text_name in texts_listed) {
text_in <- get(text_name)
coverage_anew = sum(text_in$anew_score != 0.00) / nrow(text_in) *100
print(paste0("ANEW ratings in ", text_name, ": ", round(coverage_anew,0), "%"))
coverage_vader = sum(text_in$vader_score != 0.00) / nrow(text_in) *100
print(paste0("VADER ratings in ", text_name, ": ", round(coverage_vader,0), "%"))
}
print("Coverage")
for (text_name in texts_listed) {
text_in <- get(text_name)
print(text_name)
coverage_anew = sum(text_in$anew_score != 0.00) / nrow(text_in) *100
print(paste0("ANEW ratings in: ", round(coverage_anew,0), "%"))
coverage_vader = sum(text_in$vader_score != 0.00) / nrow(text_in) *100
print(paste0("VADER ratings in: ", round(coverage_vader,0), "%"))
}
print("Coverage")
for (text_name in texts_listed) {
text_in <- get(text_name)
print(text_name)
coverage_anew = sum(text_in$anew_score != 0.00) / nrow(text_in) *100
print(paste0("ANEW ", round(coverage_anew,0), "%"))
coverage_vader = sum(text_in$vader_score != 0.00) / nrow(text_in) *100
print(paste0("VADER ", round(coverage_vader,0), "%"))
}
print("Coverage")
for (text_name in texts_listed) {
text_in <- get(text_name)
print(text_name)
coverage_anew = sum(text_in$anew_score != 0.00) / nrow(text_in) *100
coverage_vader = sum(text_in$vader_score != 0.00) / nrow(text_in) *100
print(paste0("ANEW :", round(coverage_anew,0), "%", " VADER :", round(coverage_vader,0), "%"))
}
print("Coverage")
for (text_name in texts_listed) {
text_in <- get(text_name)
print(text_name)
coverage_anew = sum(text_in$anew_score != 0.00) / nrow(text_in) *100
coverage_vader = sum(text_in$vader_score != 0.00) / nrow(text_in) *100
print(paste0("ANEW :", round(coverage_anew,0), "%, ", "VADER :", round(coverage_vader,0), "%"))
}
print("Coverage")
for (text_name in texts_listed) {
text_in <- get(text_name)
print(text_name)
coverage_anew = sum(text_in$anew_score != 0.00) / nrow(text_in) *100
coverage_vader = sum(text_in$vader_score != 0.00) / nrow(text_in) *100
print(paste0("\n","ANEW :", round(coverage_anew,0), "%, ", "VADER :", round(coverage_vader,0), "%"))
}
print("Coverage")
for (text_name in texts_listed) {
text_in <- get(text_name)
print(text_name)
coverage_anew = sum(text_in$anew_score != 0.00) / nrow(text_in) *100
coverage_vader = sum(text_in$vader_score != 0.00) / nrow(text_in) *100
print(paste0(br,"ANEW :", round(coverage_anew,0), "%, ", "VADER :", round(coverage_vader,0), "%"))
}
print("Coverage")
for (text_name in texts_listed) {
text_in <- get(text_name)
print(text_name)
coverage_anew = sum(text_in$anew_score != 0.00) / nrow(text_in) *100
coverage_vader = sum(text_in$vader_score != 0.00) / nrow(text_in) *100
print(paste0("ANEW :", round(coverage_anew,0), "%, ", "VADER :", round(coverage_vader,0), "%"))
}
print("Coverage")
for (text_name in texts_listed) {
text_in <- get(text_name)
print(text_name)
coverage_anew = sum(text_in$anew_score != 0.00) / nrow(text_in) *100
coverage_vader = sum(text_in$vader_score != 0.00) / nrow(text_in) *100
print(paste0("ANEW:", round(coverage_anew,0), "%, ", "VADER:", round(coverage_vader,0), "%"))
}
print("Coverage")
for (text_name in texts_listed) {
text_in <- get(text_name)
print(text_name)
coverage_anew = sum(text_in$anew_score != 0.00) / nrow(text_in) *100
coverage_vader = sum(text_in$vader_score != 0.00) / nrow(text_in) *100
print(paste0("ANEW: ", round(coverage_anew,0), "%, ", "VADER: ", round(coverage_vader,0), "%"))
}
print("Coverage")
for (text_name in texts_listed) {
text_in <- get(text_name)
coverage_anew = sum(text_in$anew_score != 0.00) / nrow(text_in) *100
coverage_vader = sum(text_in$vader_score != 0.00) / nrow(text_in) *100
print(paste0(text_name, " - ", "ANEW: ", round(coverage_anew,0), "%, ", "VADER: ", round(coverage_vader,0), "%"))
}
pleasure <- valence(data_dictionary_ANEW)[["pleasure"]]
View(text1)
